{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. What is Simple Linear Regression?\n",
        "\n",
        "Simple Linear Regression is a statistical method used to model the relationship between two variables:\n",
        "\n",
        "* **Independent variable (X)**: the predictor.\n",
        "* **Dependent variable (Y)**: the outcome.\n",
        "  It finds the best straight line (Y = mX + c) that predicts Y based on X.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "* There is a **linear relationship** between X and Y.\n",
        "* The residuals (errors) are **normally distributed**.\n",
        "* The residuals have **constant variance** (homoscedasticity).\n",
        "* Observations are **independent**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. What does the coefficient m represent in the equation Y = mX + c?\n",
        "\n",
        "* **m is the slope.**\n",
        "  It shows how much Y changes when X increases by one unit.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. What does the intercept c represent in the equation Y = mX + c?\n",
        "\n",
        "* **c is the intercept.**\n",
        "  It is the value of Y when X is 0. It tells where the line crosses the Y-axis.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "$m = \\frac{n(\\sum XY) - (\\sum X)(\\sum Y)}{n(\\sum X^2) - (\\sum X)^2}$\n",
        "It’s calculated using the formula based on the data points.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "It minimizes the **sum of squared errors** (difference between actual and predicted Y) to find the best-fitting line.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
        "\n",
        "R² shows **how well the model explains the variation** in Y.\n",
        "\n",
        "* R² = 1 → Perfect fit\n",
        "* R² = 0 → Model does not explain the variability\n",
        "\n",
        "---\n",
        "\n",
        "### 8. What is Multiple Linear Regression?\n",
        "\n",
        "It is a regression model with **two or more independent variables** used to predict the dependent variable.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "* **Simple Linear Regression:** One independent variable.\n",
        "* **Multiple Linear Regression:** Two or more independent variables.\n",
        "\n",
        "---\n",
        "\n",
        "### 10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "* Linear relationship\n",
        "* Independence of errors\n",
        "* Homoscedasticity (constant variance)\n",
        "* No multicollinearity\n",
        "* Errors are normally distributed\n",
        "\n",
        "---\n",
        "\n",
        "### 11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "Heteroscedasticity means the **variance of residuals is not constant**.\n",
        "It can lead to **unreliable predictions and incorrect standard errors**.\n",
        "\n",
        "---\n",
        "\n",
        "### 12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "* Remove correlated variables\n",
        "* Use **Principal Component Analysis (PCA)**\n",
        "* Standardize variables\n",
        "* Combine similar predictors\n",
        "\n",
        "---\n",
        "\n",
        "### 13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "* **One-Hot Encoding:** Create binary columns.\n",
        "* **Label Encoding:** Assign numeric labels.\n",
        "* **Dummy Variables:** Create (0,1) variables for each category.\n",
        "\n",
        "---\n",
        "\n",
        "### 14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "Interaction terms show **how the effect of one variable changes depending on another variable**. It allows us to model more complex relationships.\n",
        "\n",
        "---\n",
        "\n",
        "### 15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "* In Simple Regression: Intercept is Y when X = 0.\n",
        "* In Multiple Regression: Intercept is Y when all X variables = 0 (which might not always make real-world sense).\n",
        "\n",
        "---\n",
        "\n",
        "### 16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "The slope shows the **rate of change of Y for each unit change in X.** It tells the direction and strength of the relationship.\n",
        "\n",
        "---\n",
        "\n",
        "### 17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "It gives a **starting point** for Y when all X variables are zero. Sometimes, the intercept has meaningful interpretation, sometimes not.\n",
        "\n",
        "---\n",
        "\n",
        "### 18. What are the limitations of using R² as a sole measure of model performance?\n",
        "\n",
        "* It doesn’t tell if the model is good for prediction.\n",
        "* It increases with more variables, even if they are not useful.\n",
        "* It doesn’t detect overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 19. How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "It means the **coefficient estimate is not precise.**\n",
        "The variable may not be a reliable predictor.\n",
        "\n",
        "---\n",
        "\n",
        "### 20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "In residual plots:\n",
        "\n",
        "* Heteroscedasticity → spread of residuals increases or decreases with X.\n",
        "* Important to fix because it can make test statistics unreliable.\n",
        "\n",
        "---\n",
        "\n",
        "### 21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
        "\n",
        "It means the model might have **unnecessary variables.** Adjusted R² penalizes adding useless predictors.\n",
        "\n",
        "---\n",
        "\n",
        "### 22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "Scaling ensures that all variables contribute equally to the analysis, especially when they have **different units or ranges.**\n",
        "\n",
        "---\n",
        "\n",
        "### 23. What is polynomial regression?\n",
        "\n",
        "It is a regression where the relationship between X and Y is **curved** (not a straight line). The equation includes powers of X.\n",
        "\n",
        "---\n",
        "\n",
        "### 24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "* Linear Regression: Straight-line relationship.\n",
        "* Polynomial Regression: Curved relationship using X², X³, etc.\n",
        "\n",
        "---\n",
        "\n",
        "### 25. When is polynomial regression used?\n",
        "\n",
        "When data shows a **non-linear pattern** that cannot be captured by a straight line.\n",
        "\n",
        "---\n",
        "\n",
        "### 26. What is the general equation for polynomial regression?\n",
        "\n",
        "Y = b₀ + b₁X + b₂X² + b₃X³ + ... + bₙXⁿ\n",
        "\n",
        "---\n",
        "\n",
        "### 27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "Yes, it’s called **Multivariate Polynomial Regression** where each variable can have polynomial terms.\n",
        "\n",
        "---\n",
        "\n",
        "### 28. What are the limitations of polynomial regression?\n",
        "\n",
        "* Prone to **overfitting** with high degrees.\n",
        "* Complex to interpret.\n",
        "* Can become unstable outside the data range.\n",
        "\n",
        "---\n",
        "\n",
        "### 29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "* **Cross-Validation**\n",
        "* **Adjusted R²**\n",
        "* **Residual Analysis**\n",
        "* **AIC / BIC scores** (model selection criteria)\n",
        "\n",
        "---\n",
        "\n",
        "### 30. Why is visualization important in polynomial regression?\n",
        "\n",
        "Visualization helps:\n",
        "\n",
        "* Understand if the curve fits well.\n",
        "* Detect overfitting.\n",
        "* Show the relationship between X and Y clearly.\n",
        "\n",
        "---\n",
        "\n",
        "### 31. How is polynomial regression implemented in Python?\n",
        "\n",
        "Example using `numpy` and `sklearn`:\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Example: Degree 2 polynomial\n",
        "model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "```\n"
      ],
      "metadata": {
        "id": "wQ1YJW2ioLUJ"
      }
    }
  ]
}